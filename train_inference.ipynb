{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_inference.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2ZdUwLAA7Wxg"},"source":["Google Colabを用いる際には，Driveをマウントする必要があります．"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Dt9dCWO7Wxs","executionInfo":{"status":"ok","timestamp":1615769136144,"user_tz":-540,"elapsed":1069,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}},"outputId":"e0c86253-5f08-4b67-cc9e-c62efca51483"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LghvR49q7wwb"},"source":["**環境構築**"]},{"cell_type":"markdown","metadata":{"id":"BnY0dK6iNWS0"},"source":["リモートリポジトリからディレクトリをcloneします．あなたのgithubのidとpasswordを入力してください．"]},{"cell_type":"code","metadata":{"id":"N88B5l2L7t7J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615769138730,"user_tz":-540,"elapsed":3644,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}},"outputId":"b5629f52-e014-4478-b2f7-ad1627878d51"},"source":["git_id = ''\n","git_password = ''\n","folder_name = 'SemanticSegmentation'\n","\n","!git clone  https://$git_id:$git_password@github.com/RUTILEA/o-semantic-segmentation \"drive/My Drive\"/$folder_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fpwBXD8N9RXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615769147247,"user_tz":-540,"elapsed":12159,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}},"outputId":"cba5f689-5e92-4ea8-f955-edc522d3c76c"},"source":["%cd drive/MyDrive/$folder_name/\n","!bash requirements/get_pretained_weights.sh\n","!bash requirements/get_sample_datasets.sh\n","!pip install -r requirements/mac_0828.txt\n","%cd ../../../"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pDsIseo7Wxt"},"source":["用いるディレクトリのパスを入力します．srcやdatasetのあるメインのディレクトリ名を指定します．\n","colabの場合はそのまま，jupyterの場合はコメントアウトを変更してください．"]},{"cell_type":"code","metadata":{"id":"_iZwax0H7Wxt","executionInfo":{"status":"ok","timestamp":1615769246481,"user_tz":-540,"elapsed":111381,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}}},"source":["from pathlib import Path\n","\n","data_path = Path(f\"/content/drive/My Drive/{folder_name}\")#colabの場合\n","# data_path = Path('./')#jupyterの場合"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4julZBH_7Wxt"},"source":["src以下のライブラリをインポートするための準備をします．"]},{"cell_type":"code","metadata":{"id":"Vqf_Fo2LVJ2M","executionInfo":{"status":"ok","timestamp":1615769246482,"user_tz":-540,"elapsed":111379,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}}},"source":["import sys\n","sys.path.append(str(data_path.joinpath('src')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l4nswv5T7Wxu"},"source":["学習"]},{"cell_type":"code","metadata":{"id":"TYkS4qIVVPil","executionInfo":{"status":"ok","timestamp":1615769248003,"user_tz":-540,"elapsed":112897,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}}},"source":["import datetime\n","import collections\n","from utils import calc_weights_of_crossentropy, CallbackForSegmentation\n","import utils\n","import train\n","import numpy as np\n","import importlib\n","import train\n","importlib.reload(utils)\n","importlib.reload(train)\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau, CSVLogger"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q7_egjEr7Wxv"},"source":["用いるデータセット名を指定します．dataset内のディレクトリを指定します．データセットは指定された形である必要があります．\n","\n","`dataset/`を作成し、その中に今回使うデータセットのディレクトリ（今回は`sample/`）を準備します。\n","その中に、以下の４つのディレクトリを作成し、それぞれ画像を格納します。\n","- `dataset/sample/train/image`: 訓練用画像\n","- `dataset/sample/train/label`: 訓練用ラベル\n","- `dataset/sample/test/image`: 評価用画像\n","- `dataset/sample/test/label`: 評価用ラベル"]},{"cell_type":"code","metadata":{"id":"L7rBkg7L7Wxv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615769248004,"user_tz":-540,"elapsed":112895,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}},"outputId":"ae953fa9-0b98-4369-e328-709cf6f3b641"},"source":["#　データセット名を指定\n","dataset = 'sample'\n","\n","dataset_path = data_path.joinpath('dataset', dataset)\n","print(dataset_path)\n","\n","assert dataset_path.is_dir()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"37yjy6vq7Wxv"},"source":["ラベル情報，訓練画像のサイズ，学習の記録(これがcallbackのディレクトリ名になります)，学習時に推論するための画像データ，ラベルデータ名を定義します．\n","\n","ラベル情報はOrderedDict型で定義します。キーはクラス名、値はそのクラスのラベル画像でのRGB値としてください。\n","\n","- `img_shape`: 学習に使う画像の解像度を指定します。データセットの画像はこのサイズにランダムな位置でクロップされます。`(256, 256)`か`(512, 512)`を選択してください。これ以外のサイズにも変更可能ですが，設定の関係で4の倍数でのみ正常に作動します．\n","\n","- `params`: Data Augmentation用のパラメータです．詳しくは[こちら](https://keras.io/ja/preprocessing/image/)を見てください．\n","\n","- `description`: どういう設定で学習したらうまくいくのかを覚えておくのは難しいので、識別できるような内容をあらかじめここに書いておくのをお勧めします。形式は自由です。\n","デフォルトではデータセット名，使用モデル名，学習率の3つを記述しています．\n","\n","- `test_img_name`: 学習時に推論するための画像のデータのファイル名\n","\n","- `test_label_name`: 学習時に推論するためのラベルのデータのファイル名\n","\n","- `model_name`:`UNet`あるいは`Deeplabv3`が利用できます。"]},{"cell_type":"code","metadata":{"id":"2mIZoHC97Wxw","executionInfo":{"status":"ok","timestamp":1615769248005,"user_tz":-540,"elapsed":112888,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}}},"source":["# ラベル情報の定義(RGBの順)\n","label_info = collections.OrderedDict()\n","label_info[\"background\"] = (0, 0, 0)\n","label_info[\"genmai\"] = (0, 128, 0)\n","label_info[\"trash\"] = (128, 0, 0)\n","\n","# 訓練画像のshape (height, width, channel)\n","img_shape=(512, 512, 3)\n","\n","# Data Augmentationのパラメータ\n","params = {\n","    'rotation_range': 20,\n","    'horizontal_flip': True,\n","    'vertical_flip': True,\n","    'random_crop': img_shape[:2],\n","    'fill_mode': 'reflect',\n","}\n","\n","# 学習用のパラメータ\n","steps_per_epoch=80\n","epochs=300\n","validation_steps=8\n","batch_size=3\n","lr=1e-4  # Optimizerの学習率\n","model_name = \"Deeplabv3\" # choose model, 'Deeplabv3' or 'Unet'\n","\n","# どういう設定で学習したのかを記録する用途（形式自由）\n","description=f\"{dataset}_{model_name}_lr_{lr}\"  \n","\n","# 学習時に推論する設定\n","test_img_name='img_104.jpg'  # 画像データ\n","test_label_name='label_104.png'  # ラベルデータ"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ctv5_2Kt7Wxw"},"source":["以下，callbackの設定をします．\n","\n","`CallbackForSegmentation`は、以下の機能を提供します。\n","\n","- 各エポックの学習が終わった後のモデルで推論をし、`weights/~~~/images/`以下に結果が保存されます。ファイル名には、今のエポック数・クラス名・IoUが含まれています。\n","- Ground Truthと比較してmIoUを算出します。\n","- この値は、Keras標準で付属している`CSVLogger`によって`weights/~~~/log.csv`に保存されます。`CSVLogger`は`CallbackForSegmentation`より後ろに配置する必要があります。"]},{"cell_type":"code","metadata":{"id":"iPIYnyXXlgXJ","executionInfo":{"status":"ok","timestamp":1615769248374,"user_tz":-540,"elapsed":113252,"user":{"displayName":"窪田一誠","photoUrl":"","userId":"16994895356208567176"}}},"source":["# 下準備\n","weight_id = f\"{datetime.datetime.now().isoformat(timespec='seconds')}_{description}\"\n","weight_path = data_path.joinpath(\"weights\")\n","weight_path.mkdir(exist_ok=True)\n","weight_path = weight_path.joinpath(weight_id)\n","weight_path.mkdir(parents=True)\n","log_path = weight_path.joinpath(\"log\")\n","log_path.mkdir()\n","\n","# callbackの設定\n","ckpt = ModelCheckpoint(\n","        filepath=str(log_path / 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'),\n","        monitor='val_loss',\n","        save_best_only=True,\n","        save_freq='epoch',\n","        save_weights_only=False\n",")\n","\n","early_stop = EarlyStopping(\n","    monitor='val_mIoU',\n","    patience=15,\n","    restore_best_weights=True\n",")\n","\n","cb_for_sg = CallbackForSegmentation(\n","    validation_img_path=dataset_path/\"test/image/\"/test_img_name,\n","    ground_truth_path=dataset_path/\"test/label/\"/test_label_name,\n","    label_info=label_info,\n","    model_path=weight_path,\n","    train_img_size=(img_shape[0], img_shape[1]),\n","    period=1\n",")\n","\n","reduce_lr = ReduceLROnPlateau(min_lr=1e-6, patience=4, cooldown=2, monitor=\"val_mIoU\")\n","t_board = TensorBoard(log_dir=str(weight_path / \"board\"))\n","\n","csv = CSVLogger(filename=str(weight_path / \"log.csv\"))\n","\n","callbacks = [cb_for_sg, ckpt, early_stop, reduce_lr, csv]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aovNqV0e7Wxx"},"source":["学習を行います．学習済みのモデルを読み込む場合には，最初のmodelと，train.run内のmodelのコメントアウトを戻してください．\n","学習率，バッチサイズ等，任意に変更することができます．\n","\n","- `weights_of_crossentropy`: このライブラリでは普通の交差エントロピーではなく、重み付き交差エントロピーを用いています。\n","これにより、クラス間で出現頻度に大きな偏りがある場合でも効率よく学習を進められます。\n","`calc_weights_of_crossentropy`関数を用いることで、それぞれのクラスの出現数から自動的に適した重みを算出できます。`* np.array([1., 3., 1.])`のように、さらにそれに重み付けをすることができます。"]},{"cell_type":"code","metadata":{"id":"TbUa9Eo27Wxx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f906e3bc-2a0e-47a5-f6d0-9b3add4cec00"},"source":["# 学習済みモデルの読み込み\n","# model = load_model(filepath=\"\", custom_objects={\"weighted_cross_entropy\": weighted_crossentropy_wrapper(base_weights_of_crossentropy), 'tf': tf})\n","\n","base_weights_of_crossentropy = calc_weights_of_crossentropy(dataset_path=dataset_path, label_info=label_info)\n","print(\"base_weights_of_crossentropy:\", base_weights_of_crossentropy)\n","\n","print(f\"##### START ######\\n{weight_id}\")\n","train.run(\n","        img_shape=img_shape,\n","        params=params,\n","        steps_per_epoch=steps_per_epoch,\n","        epochs=epochs,\n","        validation_steps=validation_steps,\n","        batch_size=batch_size,\n","        lr=lr,  # Optimizerの学習率\n","        weights_of_crossentropy=base_weights_of_crossentropy * np.array([1., 3., 1.,]),\n","        dataset_path=dataset_path,\n","        weight_path=weight_path,\n","        model_name=model_name,\n","        callbacks = callbacks,\n","        # model=model,\n","        label_info=label_info,\n","        description=description,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pu19KEvQlkm_"},"source":["推論"]},{"cell_type":"code","metadata":{"id":"ZDvTUudellkY"},"source":["from tensorflow.keras.models import load_model, Model\n","from utils import weighted_crossentropy_wrapper, get_paths_in_dir\n","import tensorflow as tf\n","import inference\n","importlib.reload(inference)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D_59ZQxB7Wxz"},"source":["推論に使用するモデルのh5ファイルの絶対パスや，フォルダ名等を指定してください．\n","\n","ModelCheckpointによって保存された`log/`内のweightも指定できます。\n","\n","ラベル情報や`train_img_size`は，学習の時に用いたものと同じものを定義します。\n"]},{"cell_type":"code","metadata":{"id":"C5x8SP6KlnMJ"},"source":["# パス・名前の設定\n","weight_path = Path(\"\")  # 使うモデルの設定\n","target_name = \"genmai_masked\"  # inference_targetの中のフォルダ名\n","result_name = \"genmai_masked_01\"  # inference_resultの作成するフォルダ名\n","\n","label_info = collections.OrderedDict()\n","label_info[\"background\"] = (0, 0, 0)  # RGB\n","label_info[\"genmai\"] = (0, 128, 0)\n","label_info[\"trash\"] = (128, 0, 0)\n","\n","\n","target_dir_path = data_path.joinpath(\"inference_target\", target_name)\n","result_path = data_path.joinpath(\"inference_result\", result_name)\n","result_path.mkdir(exist_ok=True)\n","assert weight_path.is_file() and target_dir_path.is_dir()\n","model: Model = load_model(str(weight_path), custom_objects={\"weighted_cross_entropy\": weighted_crossentropy_wrapper([1., 60., 60.]), 'tf': tf})\n","image_paths = get_paths_in_dir(target_dir_path)\n","\n","\n","for target_img_path in image_paths:\n","    print(\"processing...\")\n","    inference.run_inference(target_img_path=target_img_path, label_info=label_info, model=model, train_img_size=(512, 512), result_path=result_path)\n"],"execution_count":null,"outputs":[]}]}